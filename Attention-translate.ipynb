{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:01.597393Z",
     "start_time": "2018-09-27T16:39:59.994136Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from fastai import DataBunch\n",
    "from fastai import Learner\n",
    "from fastai import Callback\n",
    "from fastai.callback import Stepper\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.backends.cudnn.enabled = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:01.601408Z",
     "start_time": "2018-09-27T16:40:01.598397Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:02.265669Z",
     "start_time": "2018-09-27T16:40:01.602410Z"
    }
   },
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path + 'rus.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[:-1]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"_bos_\" as the \"start of sequence\" token\n",
    "    # for the targets, and \"_eos_\" as \"end of sequence\" token\n",
    "    input_text = '_bos_ ' + input_text + ' _eos_'\n",
    "    target_text = '_bos_ ' + target_text + ' _eos_'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "\n",
    "num_samples = len(input_texts)\n",
    "vocab_size = 50000\n",
    "\n",
    "from itertools import chain\n",
    "max_len = max(list(chain.from_iterable((len(x.split(' ')), len(y.split(' '))) for x, y in zip(input_texts, target_texts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:02.823120Z",
     "start_time": "2018-09-27T16:40:02.266672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 304513\n",
      "Max sequence length for inputs: 45\n",
      "Max sequence length for outputs: 42\n",
      "Median sequence length for inputs: 8.0\n",
      "Median sequence length for outputs: 7.0\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', num_samples)\n",
    "print('Max sequence length for inputs:', max([len(txt.split(' ')) for txt in input_texts]))\n",
    "print('Max sequence length for outputs:', max([len(txt.split(' ')) for txt in target_texts]))\n",
    "print('Median sequence length for inputs:', np.median([len(txt.split(' ')) for txt in input_texts]))\n",
    "print('Median sequence length for outputs:', np.median([len(txt.split(' ')) for txt in target_texts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.264198Z",
     "start_time": "2018-09-27T16:40:02.824122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761 1\n",
      "711 1\n",
      "2 2\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "en_tokenizer = Tokenizer(num_words=vocab_size, lower=True, split=' ', oov_token='OOV', filters='')\n",
    "ru_tokenizer = Tokenizer(num_words=vocab_size, lower=True, split=' ', oov_token='OOV', filters='')\n",
    "en_tokenizer.fit_on_texts(input_texts)\n",
    "ru_tokenizer.fit_on_texts(target_texts)\n",
    "\n",
    "x_t = np.asarray(en_tokenizer.texts_to_sequences(input_texts))\n",
    "y_t = np.asarray(ru_tokenizer.texts_to_sequences(target_texts))\n",
    "print(en_tokenizer.word_index['coffee'], en_tokenizer.word_index['OOV'])\n",
    "print(ru_tokenizer.word_index['кофе'], ru_tokenizer.word_index['OOV'])\n",
    "print(en_tokenizer.word_index['_bos_'], en_tokenizer.word_index['_bos_'])\n",
    "print(ru_tokenizer.word_index['_eos_'], ru_tokenizer.word_index['_eos_'])\n",
    "\n",
    "x_t = pad_sequences(x_t, maxlen=max_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "y_t = pad_sequences(y_t, maxlen=max_len, dtype='int32', padding='post', truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.272727Z",
     "start_time": "2018-09-27T16:40:20.265202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('_bos_ Go. _eos_', '_bos_ Иди. _eos_')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[0], target_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.281771Z",
     "start_time": "2018-09-27T16:40:20.273742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2, 205,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0]),\n",
       " array([    2, 11701,     3,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " (304513, 45))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[0], y_t[0], x_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "#crop = 40000\n",
    "#x_t = x_t[0:crop]\n",
    "#y_t = y_t[0:crop]\n",
    "x_trn, x_val, y_trn, y_val = train_test_split(x_t, y_t, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.393543Z",
     "start_time": "2018-09-27T16:40:20.283777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([274061, 45])\n",
      "y shape torch.Size([274061, 45])\n",
      "x shape torch.Size([30452, 45])\n",
      "y shape torch.Size([30452, 45])\n"
     ]
    }
   ],
   "source": [
    "bs=16\n",
    "\n",
    "class TokDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x; self.y = y\n",
    "        self.len = len(self.x)\n",
    "        self.x_data = torch.from_numpy(self.x); self.x_data = self.x_data.long()\n",
    "        self.y_data = torch.from_numpy(self.y); self.y_data = self.y_data.long()\n",
    "        print('x shape', self.x_data.shape)\n",
    "        print('y shape', self.y_data.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "ds = TokDataset(x_trn, y_trn)\n",
    "ds_val = TokDataset(x_val, y_val)\n",
    "dl = torch.utils.data.DataLoader(dataset=ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "dl_val = torch.utils.data.DataLoader(dataset=ds_val, batch_size=bs, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274061, 45)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 274061)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trn.transpose().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.410579Z",
     "start_time": "2018-09-27T16:40:20.394544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 16]) torch.Size([45, 16])\n"
     ]
    }
   ],
   "source": [
    "# Values for testing\n",
    "test_values = iter(dl)\n",
    "xs, ys = next(test_values)\n",
    "xs, ys = xs.t(), ys.t()\n",
    "print(xs.shape, ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a random variable, as a Parameter (Parameter tells PyTorch to learn the weights for that tensor)\n",
    "def rand_p(*sz): return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:42:38.089470Z",
     "start_time": "2018-09-27T16:42:37.999253Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionRNN(nn.Module):\n",
    "    def __init__(self, inp_sz, out_sz, em_sz, h_sz, n_l, voc_sz, t_frc=0.95):\n",
    "        super().__init__()\n",
    "        self.em_sz, self.h_sz, self.n_l, self.inp_sz, self.out_sz, self.voc_sz, self.t_frc = em_sz, h_sz, n_l, inp_sz, out_sz, voc_sz, t_frc\n",
    "        # Encoder\n",
    "        self.enc_em = nn.Embedding(voc_sz, em_sz)\n",
    "        self.em_drp = nn.Dropout(0.15)\n",
    "        self.enc_gru = nn.GRU(em_sz, h_sz, num_layers=n_l, dropout=0.2, bidirectional=True)\n",
    "        # h_sz*2 because of bidir\n",
    "        self.enc_out = nn.Linear(h_sz*2, em_sz, bias=False)\n",
    "        self.enc_drp = nn.Dropout(0.3)\n",
    "        # Decoder\n",
    "        self.dec_em = nn.Embedding(voc_sz, em_sz)\n",
    "        self.dec_gru = nn.GRU(em_sz, em_sz, num_layers=n_l, dropout=0.2)\n",
    "        self.dec_out = nn.Linear(em_sz, voc_sz)\n",
    "        \n",
    "        # Attention weights\n",
    "        # Initialize a random weight matrix, without bias (hidden layer), *2 because bidir\n",
    "        self.W1 = rand_p(h_sz*2, em_sz)\n",
    "        # Linear layer with bias\n",
    "        self.l2 = nn.Linear(em_sz, em_sz)\n",
    "        # Linear layer with bias with the last layer concatenated to the embeddings \n",
    "        self.l3 = nn.Linear(em_sz+h_sz*2, em_sz)\n",
    "        # Initialize a random weight matrix for the output, without bias (hidden layer)\n",
    "        self.V = rand_p(em_sz)\n",
    "        \n",
    "        # If using pretrained word embeddings:\n",
    "        #self.out.weight.data = self.enc_em.weight.data\n",
    "        \n",
    "    def forward(self, inp, y=None, ret_attn=False):\n",
    "        # seq_len, bs\n",
    "        sl, bs = inp.shape\n",
    "        h = self.initHidden(bs)\n",
    "        x = self.em_drp(self.enc_em(inp))\n",
    "        enc_outp, h = self.enc_gru(x, h)\n",
    "        # Reshape, to bidir, n_l x bs x -1\n",
    "        # Permute using indexes to change order of shape (n_l x bs x bidir(2) x n_h)\n",
    "        # Contiguous to copy the tensor\n",
    "        # Reshape to flatten the bidir layers, final shape n_l x bs x n_h*2\n",
    "        h = h.view(2,self.n_l,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        # Is it really supposed to be dropout on h instead of enc_out?\n",
    "        h = self.enc_out(self.enc_drp(h))\n",
    "        \n",
    "        dec_inp = torch.zeros(bs).long().cuda()\n",
    "        result, attentions = [], []\n",
    "        # Matrix multiply the encoder output with the W1 weight matrix\n",
    "        # This is basically a linear layer pass through, without the bias\n",
    "        w1e = enc_outp @ self.W1\n",
    "        # Loop over max output size\n",
    "        for i in range(self.out_sz):\n",
    "            # Pass the hidden state through a hidden layer with bias\n",
    "            w2h = self.l2(h[-1])\n",
    "            # Add the attention weights of all the outputs from enc_out (w1e), and the last hidden state (w2h)\n",
    "            # And pass through a non linear activation function\n",
    "            u = torch.tanh(w1e + w2h)\n",
    "            # Pass the activations through the last layer and activate with a softmax\n",
    "            a = F.softmax(u @ self.V, dim=0)\n",
    "            # Store attentions, for returning them for visualization\n",
    "            attentions.append(a)\n",
    "            # Instead of just using the last hidden state (like if we don't use attention), \n",
    "            # multiply attention with the decoder output and sum it\n",
    "            Xa = (a.unsqueeze(2) * enc_outp).sum(0)\n",
    "            \n",
    "            # Get embedding\n",
    "            emb = self.dec_em(dec_inp)\n",
    "            # Pass the concat the decoder embeddings with the attentions\n",
    "            enc_wgt = self.l3(torch.cat([emb, Xa], dim=1))\n",
    "            \n",
    "            # Pass hidden state from (initially) self.enc_out and attentioned embedding to self.dec_gru\n",
    "            outp, h = self.dec_gru(enc_wgt.unsqueeze(0), h)\n",
    "            # Pass decoder output to dense, get probabilities of words in len of vocab_size\n",
    "            outp = self.dec_out(self.enc_drp(outp[0]))\n",
    "            # Teacher forcing\n",
    "            \n",
    "            # Append the output to result\n",
    "            result.append(outp)\n",
    "            # Get new input\n",
    "            # Get ind of biggest value for each batch \n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            # If all are padding break and return\n",
    "            if (dec_inp==0).all():\n",
    "                break\n",
    "            # Teacher forcing (replaces predicted value with ground truth)\n",
    "            if (y is not None and self.t_frc > 0) and (random.random() < self.t_frc): \n",
    "                # If the len of i >= len of y, break and return\n",
    "                if i >= len(y): break\n",
    "                # else change the next dec inp to be the ground truth y\n",
    "                dec_inp = y[i]\n",
    "            \n",
    "        # Turn list of tensors into tensor\n",
    "        result = torch.stack(result)\n",
    "        # If returning attentions\n",
    "        if ret_attn: result = res, torch.stack(attentions)\n",
    "        return result\n",
    "    \n",
    "    def initHidden(self, bs): \n",
    "        # Num_layers, batch size, num hidden\n",
    "        # n_l*2 because of bidir\n",
    "        return torch.zeros(self.n_l*2, bs, self.h_sz).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:42:39.160395Z",
     "start_time": "2018-09-27T16:42:38.783755Z"
    }
   },
   "outputs": [],
   "source": [
    "em_sz = 150\n",
    "n_h = 64\n",
    "n_l = 2\n",
    "\n",
    "inp_sz = max_len\n",
    "model = AttentionRNN(inp_sz, max_len, em_sz, n_h, n_l, vocab_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:42:40.645898Z",
     "start_time": "2018-09-27T16:42:40.023981Z"
    }
   },
   "outputs": [],
   "source": [
    "test_out = model(xs.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 16, 50000])\n",
      "torch.Size([47, 16, 50000])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test_out.shape)\n",
    "# Padding example\n",
    "print(torch.nn.functional.pad(test_out, (0,0,0,0,0,2)).shape)\n",
    "# Last seq_len value is padded, so the sum of the vocab_size probs is 0\n",
    "print(int(torch.sum(torch.nn.functional.pad(test_out, (0,0,0,0,0,2))[-1].view(-1)).data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTION\n",
    "def seq2seq_loss(input, target):\n",
    "    # seq_len, bs\n",
    "    sl,bs = target.size()\n",
    "    # seq_len, bs, num_channels (vocab size)\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    # If the output sl is smaller than the actual sl, pad it.\n",
    "    # The shape of input is 'sl x bs x vocab_sz'\n",
    "    # The reason why have more 0's for padding, is because in PyTorch\n",
    "    # You have padding on the left, and right, so none on sl or bs or nc left side, but pad on right\n",
    "    # In this case, pad seq_len on the right by the difference between grount truth sl and input sl\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    # If its too long, just crop it\n",
    "    input = input[:sl]\n",
    "    # Cross entropy expects a rank 2 tensor, so flatten the seq_len\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastai DataBunch and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_bunch = DataBunch(dl, dl_val)\n",
    "learn = Learner(d_bunch, model, loss_fn=seq2seq_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast.ai custom step function callback\n",
    "class Seq2seqStepper(Stepper):\n",
    "    def step(self, xs, y, t_frc):\n",
    "        super().step()\n",
    "        t_frc = (10 - epoch)*0.1 if epoch>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seqCallback(Callback):\n",
    "    def step(self, xs, y, t_frc):\n",
    "        super().step()\n",
    "        t_frc = (10 - epoch)*0.1 if epoch>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, xs, y, t_frc):\n",
    "    super().step()\n",
    "    t_frc = (10 - epoch)*0.1 if epoch>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepper = Stepper([0, 10], 1, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-45f957babce6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#learn.fit_one_cycle(2, lr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#learn.fit(2, lr, callbacks=[stepper])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO use clr \n",
    "# fit_one_cycle fits a model following the 1cycle policy.\n",
    "#learn.fit_one_cycle(2, lr)\n",
    "#learn.fit(2, lr, callbacks=[stepper])\n",
    "learn.fit(2, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3ed1c6060576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'initial'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "learn.save('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non fastai fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_dl, crit, opt, verb=200):\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for i, data in tqdm(enumerate(train_dl)):\n",
    "            x, y = data\n",
    "            x = x.t().cuda(); y = y.t().cuda()\n",
    "\n",
    "            y_h = model(x, y=y)#, y=y)\n",
    "            loss = crit(y_h, y)\n",
    "\n",
    "            if i % verb == 0:\n",
    "                print(f' Epoch: {ep} | b_loss: {loss.item():.{4}f}')\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 10.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:01,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:07,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 9.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:14,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [04:23,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:33,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [06:43,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [07:52,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.8840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1600it [09:02,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 9.1878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1800it [10:11,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.4450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [11:22,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2200it [12:33,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.8403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2400it [13:42,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2600it [14:49,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.1577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2800it [15:56,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [17:03,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3200it [18:09,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3400it [19:17,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.4510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3600it [20:28,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.4181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3800it [21:38,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [22:49,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 9.1460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4200it [23:58,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.2328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4400it [25:08,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4600it [26:17,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4800it [27:27,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.8607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [28:39,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.3815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5200it [29:47,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5400it [30:59,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5600it [32:10,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5800it [33:20,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.5862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6000it [34:30,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6200it [35:41,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.4291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6400it [36:51,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 9.1630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6600it [38:03,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6800it [39:14,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.4808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [40:25,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.8717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7200it [41:37,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.9806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7400it [42:48,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.4051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [43:58,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.1614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7800it [45:08,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.7845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [46:19,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 9.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8200it [47:29,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8400it [48:38,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.2862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8600it [49:48,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.7885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8800it [50:56,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9000it [52:03,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 9.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9200it [53:10,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.8666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9400it [54:19,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9600it [55:31,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9800it [56:39,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 9.1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [57:49,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.5295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10200it [59:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 7.6409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10400it [1:00:11,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.4928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10600it [1:01:21,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.4206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10800it [1:02:31,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 9.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11000it [1:03:42,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11200it [1:04:52,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.6418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11400it [1:06:01,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.1720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11600it [1:07:12,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 6.7015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11800it [1:08:23,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.0279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12000it [1:09:33,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 6.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12200it [1:10:43,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.3256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12400it [1:11:53,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | b_loss: 8.3146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12557it [1:12:47,  2.91it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-1ed0202f3784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq2seq_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-617daf0b8249>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, model, train_dl, crit, opt, verb)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                     \u001b[1;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "fit(20, model, dl, seq2seq_loss, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-23T10:58:26.564284Z",
     "start_time": "2018-09-23T10:58:26.547745Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "###RUN THROUGH DL2 TRANSLATE NOTEBOOK AND ANSWER THESE QUESTIONS\n",
    "#########################################\n",
    "## WHAT IS \n",
    "\n",
    "#vecs_enc - \n",
    "    # Dict of words, with embedding vectors values\n",
    "    # https://i.imgur.com/nIELpdY.png\n",
    "    # https://i.imgur.com/RgBnu4O.png\n",
    "#itos_enc - \n",
    "    # Index to string\n",
    "    # List of strings, of which the list index is pointing to a word\n",
    "    # https://i.imgur.com/oq6Kcv1.png\n",
    "    # https://i.imgur.com/dXSh60V.png\n",
    "#vecs_dec - Same as vecs_enc, but for dec\n",
    "#itos_dec - Same as itos_enc but for dec\n",
    "#########################################\n",
    "##WHAT DOES create_emb DO\n",
    "    # Makes an embedding with wiki vectors weights tripled \n",
    "## WHAT IS THE sl,bs IN inp.size()\n",
    "    # bs is batch size\n",
    "    # sl is seq_len https://i.imgur.com/icfxqv9.png\n",
    "\n",
    "##WHAT DOES THE FOR LOOP IN FORWARD DO\n",
    "    # Get encoder input values from embeddings\n",
    "    # Send enc hidden and embedding to decoder gru\n",
    "    # Get highest value per patch\n",
    "    # Append to result\n",
    "\n",
    "##WHY DO YOU TAKE WEIGHT DATA OF OUTPUT EMBEDDINGS (IS THAT RELATED TO THE RETURN?)\n",
    "# if you aren't using pre-trained embeddings then it's not really doing anything, all it's doing is making sure the weights of the embedding layer and the weights of the output layer are initialized to the same values\n",
    "# it's sometimes referred to as \"weight tying\"\n",
    "# https://arxiv.org/pdf/1611.01462.pdf\n",
    "# however, in this case they're only initialized to the same value and will probably end up  diverging to different sets of weights\n",
    "\n",
    "##########################################\n",
    "###FIGURE OUT THE LOSS FUNCTION\n",
    "    # Commented\n",
    "    ## WHY DO YOU PAD THE INPUT LIKE THAT\n",
    "        # Commented\n",
    "    ## WHY DO YOU SLICE THE INPUT\n",
    "        # Commented\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:25.249402Z",
     "start_time": "2018-09-22T11:58:25.247405Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONVERT IT TO BIDIR\n",
    "    # Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:08.624959Z",
     "start_time": "2018-09-22T11:58:08.622955Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEACHER FORCING\n",
    "    # Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:15.176179Z",
     "start_time": "2018-09-22T11:58:15.174175Z"
    }
   },
   "outputs": [],
   "source": [
    "# ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:34.922938Z",
     "start_time": "2018-09-22T11:58:34.920934Z"
    }
   },
   "outputs": [],
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN PROPERLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:59:06.256912Z",
     "start_time": "2018-09-22T11:59:06.254906Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONVERT MODEL TO PRDOCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_itos = dict(map(reversed, en_tokenizer.word_index.items()))\n",
    "ru_itos = dict(map(reversed, ru_tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_bos_ what happened to the other one? _eos_\n",
      "_bos_ а что с другой? _eos_\n",
      "OOV надеюсь, OOV OOV OOV OOV в когда это я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я\n",
      "\n",
      "_bos_ do you miss boston? _eos_\n",
      "_bos_ скучаете по бостону? _eos_\n",
      "OOV что OOV OOV OOV OOV школе у OOV в думал, тебя буду не не не не не не не не буду не хотел не не не не не не не хотел не не не не хочу стал не не что-то бы не хотел не\n",
      "\n",
      "_bos_ how many schools are there in your city? _eos_\n",
      "_bos_ в твоем городе сколько OOV _eos_\n",
      "OOV я чтобы вам в OOV месте меня от этом _eos_ скрывает. сделал. сказал? прав. ел. хотел знаю. знаю. прав. хотел найдёт. прав. сказать. хотел буду собираюсь буду буду хотел буду да. хотел прав. прав. счастлив. помочь. согласен. могу буду нравишься. счастлив. сказал? сказать. видел.\n",
      "\n",
      "_bos_ it became dark before i knew it. _eos_\n",
      "_bos_ я и заметить не OOV как стемнело. _eos_\n",
      "OOV сделал бы слишком последний меня не есть OOV _eos_ _eos_ _eos_ _eos_ _eos_ _eos_ сделать. _eos_ _eos_ _eos_ да. _eos_ _eos_ _eos_ сделать. _eos_ читать. _eos_ знаю. поговорить. сделать. _eos_ врать. _eos_ _eos_ _eos_ _eos_ _eos_ быть _eos_ _eos_ _eos_ _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ i've forgotten your number. _eos_\n",
      "_bos_ я забыла твой номер. _eos_\n",
      "OOV то, OOV не OOV OOV было с OOV _eos_ _eos_ _eos_ _eos_ _eos_ _eos_ _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ that's not a coincidence. _eos_\n",
      "_bos_ это не совпадение. _eos_\n",
      "OOV что всё OOV OOV OOV было собой _eos_ _eos_\n",
      "\n",
      "_bos_ the light was on. _eos_\n",
      "_bos_ свет горел. _eos_\n",
      "OOV ты OOV OOV OOV OOV в OOV\n",
      "\n",
      "_bos_ i called you three hours ago. _eos_\n",
      "_bos_ я звонил тебе три часа назад. _eos_\n",
      "OOV же OOV о OOV OOV прошлом _eos_\n",
      "\n",
      "_bos_ i couldn't have done it without you. thank you. _eos_\n",
      "_bos_ я бы не смогла это сделать без вас. спасибо. _eos_\n",
      "OOV OOV OOV том, OOV меня OOV\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(dl_val))\n",
    "probs = model(x.cuda())\n",
    "preds = probs.max(2)[1].cpu().numpy()\n",
    "x,y = x.cpu().numpy(), y.cpu().numpy()\n",
    "\n",
    "for i in range(1,10):\n",
    "    print(' '.join([en_itos[o] for o in x[i, :] if o != 0]))\n",
    "    print(' '.join([ru_itos[o] for o in y[i, :] if o != 0]))\n",
    "    print(' '.join([ru_itos[o] for o in preds[i,:] if o!=0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (baseenv)",
   "language": "python",
   "name": "baseenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
