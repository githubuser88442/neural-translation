{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:01.597393Z",
     "start_time": "2018-09-27T16:39:59.994136Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import Dataset\n",
    "from fastai import DataBunch\n",
    "from fastai import Learner\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.enabled = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:01.601408Z",
     "start_time": "2018-09-27T16:40:01.598397Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:02.265669Z",
     "start_time": "2018-09-27T16:40:01.602410Z"
    }
   },
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path + 'rus.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[:-1]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"_bos_\" as the \"start of sequence\" token\n",
    "    # for the targets, and \"_eos_\" as \"end of sequence\" token\n",
    "    input_text = '_bos_ ' + input_text + ' _eos_'\n",
    "    target_text = '_bos_ ' + target_text + ' _eos_'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "\n",
    "num_samples = len(input_texts)\n",
    "vocab_size = 50000\n",
    "\n",
    "from itertools import chain\n",
    "max_len = max(list(chain.from_iterable((len(x.split(' ')), len(y.split(' '))) for x, y in zip(input_texts, target_texts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:02.823120Z",
     "start_time": "2018-09-27T16:40:02.266672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 304513\n",
      "Max sequence length for inputs: 45\n",
      "Max sequence length for outputs: 42\n",
      "Median sequence length for inputs: 8.0\n",
      "Median sequence length for outputs: 7.0\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', num_samples)\n",
    "print('Max sequence length for inputs:', max([len(txt.split(' ')) for txt in input_texts]))\n",
    "print('Max sequence length for outputs:', max([len(txt.split(' ')) for txt in target_texts]))\n",
    "print('Median sequence length for inputs:', np.median([len(txt.split(' ')) for txt in input_texts]))\n",
    "print('Median sequence length for outputs:', np.median([len(txt.split(' ')) for txt in target_texts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.264198Z",
     "start_time": "2018-09-27T16:40:02.824122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761 1\n",
      "711 1\n",
      "2 2\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "en_tokenizer = Tokenizer(num_words=vocab_size, lower=True, split=' ', oov_token='OOV', filters='')\n",
    "ru_tokenizer = Tokenizer(num_words=vocab_size, lower=True, split=' ', oov_token='OOV', filters='')\n",
    "en_tokenizer.fit_on_texts(input_texts)\n",
    "ru_tokenizer.fit_on_texts(target_texts)\n",
    "\n",
    "x_t = np.asarray(en_tokenizer.texts_to_sequences(input_texts))\n",
    "y_t = np.asarray(ru_tokenizer.texts_to_sequences(target_texts))\n",
    "print(en_tokenizer.word_index['coffee'], en_tokenizer.word_index['OOV'])\n",
    "print(ru_tokenizer.word_index['кофе'], ru_tokenizer.word_index['OOV'])\n",
    "print(en_tokenizer.word_index['_bos_'], en_tokenizer.word_index['_bos_'])\n",
    "print(ru_tokenizer.word_index['_eos_'], ru_tokenizer.word_index['_eos_'])\n",
    "\n",
    "x_t = pad_sequences(x_t, maxlen=max_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "y_t = pad_sequences(y_t, maxlen=max_len, dtype='int32', padding='post', truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.272727Z",
     "start_time": "2018-09-27T16:40:20.265202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('_bos_ Go. _eos_', '_bos_ Иди. _eos_')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[0], target_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.281771Z",
     "start_time": "2018-09-27T16:40:20.273742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2, 205,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0]),\n",
       " array([    2, 11701,     3,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " (304513, 45))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[0], y_t[0], x_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "x_trn, x_val, y_trn, y_val = train_test_split(x_t, y_t, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.393543Z",
     "start_time": "2018-09-27T16:40:20.283777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([274061, 45])\n",
      "y shape torch.Size([274061, 45])\n",
      "x shape torch.Size([30452, 45])\n",
      "y shape torch.Size([30452, 45])\n"
     ]
    }
   ],
   "source": [
    "bs=16\n",
    "\n",
    "class TokDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x; self.y = y\n",
    "        self.len = len(self.x)\n",
    "        self.x_data = torch.from_numpy(self.x); self.x_data = self.x_data.long()\n",
    "        self.y_data = torch.from_numpy(self.y); self.y_data = self.y_data.long()\n",
    "        print('x shape', self.x_data.shape)\n",
    "        print('y shape', self.y_data.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "ds = TokDataset(x_trn, y_trn)\n",
    "ds_val = TokDataset(x_val, y_val)\n",
    "dl = torch.utils.data.DataLoader(dataset=ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "dl_val = torch.utils.data.DataLoader(dataset=ds_val, batch_size=bs, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.410579Z",
     "start_time": "2018-09-27T16:40:20.394544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 16]) torch.Size([45, 16])\n"
     ]
    }
   ],
   "source": [
    "# Values for testing\n",
    "test_values = iter(dl)\n",
    "xs, ys = next(test_values)\n",
    "xs, ys = xs.t(), ys.t()\n",
    "print(xs.shape, ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:42:38.089470Z",
     "start_time": "2018-09-27T16:42:37.999253Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionRNN(nn.Module):\n",
    "    def __init__(self, inp_sz, out_sz, em_sz, h_sz, n_l, voc_sz):\n",
    "        super().__init__()\n",
    "        self.em_sz, self.h_sz, self.n_l, self.inp_sz, self.out_sz, self.voc_sz = em_sz, h_sz, n_l, inp_sz, out_sz, voc_sz\n",
    "        # Encoder\n",
    "        self.enc_em = nn.Embedding(self.voc_sz, self.em_sz)\n",
    "        self.em_drp = nn.Dropout(0.15)\n",
    "        self.enc_gru = nn.GRU(self.em_sz, self.h_sz, num_layers=self.n_l, dropout=0.2, bidirectional=True)\n",
    "        # h_sz*2 because of bidir\n",
    "        self.enc_out = nn.Linear(self.h_sz*2, self.em_sz, bias=False)\n",
    "        self.enc_drp = nn.Dropout(0.3)\n",
    "        # Decoder\n",
    "        self.dec_em = nn.Embedding(self.voc_sz, self.em_sz)\n",
    "        self.dec_gru = nn.GRU(self.em_sz, self.em_sz, num_layers=self.n_l, dropout=0.2)\n",
    "        self.dec_out = nn.Linear(self.em_sz, self.voc_sz)\n",
    "        #self.out.weight.data = self.enc_em.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        # seq_len, bs\n",
    "        sl, bs = inp.shape\n",
    "        h = self.initHidden(bs)\n",
    "        x = self.em_drp(self.enc_em(inp))\n",
    "        enc_gru_out, h = self.enc_gru(x, h)\n",
    "        # Reshape, to bidir, n_l x bs x -1\n",
    "        # Permute using indexes to change order of shape (n_l x bs x bidir(2) x n_h)\n",
    "        # Contiguous to copy the tensor\n",
    "        # Reshape to flatten the bidir layers, final shape n_l x bs x n_h*2\n",
    "        h = h.view(2,self.n_l,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.enc_drp(self.enc_out(h))\n",
    "        \n",
    "        dec_inp = torch.zeros(bs).long().cuda()\n",
    "        result = []\n",
    "        # What is this?\n",
    "        for i in range(self.out_sz):\n",
    "            # Get embedding\n",
    "            emb = self.dec_em(dec_inp).unsqueeze(0)\n",
    "            # Pass hidden state from (initially) self.enc_out and embedding to dec gru\n",
    "            outp, h = self.dec_gru(emb, h)\n",
    "            # Pass decoder output to dense, get probabilities of words in len of vocab_size\n",
    "            outp = self.dec_out(self.enc_drp(outp[0]))\n",
    "            result.append(outp)\n",
    "            # Get ind of biggest value for each batch \n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            # If all are padding break\n",
    "            if (dec_inp==0).all():\n",
    "                break\n",
    "        # Turn list of tensors into tensor\n",
    "        return torch.stack(result)\n",
    "    \n",
    "    def initHidden(self, bs): \n",
    "        # Num_layers, batch size, num hidden\n",
    "        # n_l*2 because of bidir\n",
    "        return torch.zeros(self.n_l*2, bs, self.h_sz).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:42:39.160395Z",
     "start_time": "2018-09-27T16:42:38.783755Z"
    }
   },
   "outputs": [],
   "source": [
    "em_sz = 150\n",
    "n_h = 64\n",
    "n_l = 2\n",
    "\n",
    "inp_sz = max_len\n",
    "model = AttentionRNN(inp_sz, max_len, em_sz, n_h, n_l, vocab_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:42:40.645898Z",
     "start_time": "2018-09-27T16:42:40.023981Z"
    }
   },
   "outputs": [],
   "source": [
    "test_out = model(xs.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 16, 50000])\n",
      "torch.Size([47, 16, 50000])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test_out.shape)\n",
    "# Padding example\n",
    "print(torch.nn.functional.pad(test_out, (0,0,0,0,0,2)).shape)\n",
    "# Last seq_len value is padded, so the sum of the vocab_size probs is 0\n",
    "print(int(torch.sum(torch.nn.functional.pad(test_out, (0,0,0,0,0,2))[-1].view(-1)).data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://course.fast.ai/lessons/lesson11.html\n",
    "# http://forums.fast.ai/t/part-2-lesson-11-wiki/14699\n",
    "# 1 hour in\n",
    "def seq2seq_loss(input, target):\n",
    "    # seq_len, bs\n",
    "    sl,bs = target.size()\n",
    "    # seq_len, bs, num_channels (vocab size)\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    # If the output sl is smaller than the actual sl, pad it.\n",
    "    # The shape of input is 'sl x bs x vocab_sz'\n",
    "    # The reason why have more 0's for padding, is because in PyTorch\n",
    "    # You have padding on the left, and right, so none on sl or bs or nc left side, but pad on right\n",
    "    # In this case, pad seq_len on the right by the difference between grount truth sl and input sl\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    # If its too long, just crop it\n",
    "    input = input[:sl]\n",
    "    # Cross entropy expects a rank 2 tensor, so flatten the seq_len\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastai DataBunch and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_bunch = DataBunch(dl, dl_val)\n",
    "learn = Learner(d_bunch, model, loss_fn=seq2seq_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de103f5d9424f598e8cadbe8990ee80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=1), HTML(value='0.00% [0/1 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7574ff102544529e4ee47229cd1b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=2), HTML(value='0.00% [0/2 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-794c39fd14bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO use clr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# fit_one_cycle fits a model following the 1cycle policy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.fit(1, lr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[1;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, **kwargs)\u001b[0m\n\u001b[0;32m     16\u001b[0m     cbs = [OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[0;32m     17\u001b[0m                              pct_start=pct_start, **kwargs)]\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         fit(epochs, self.model, self.loss_fn, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[1;32m--> 133\u001b[1;33m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, model, loss_fn, opt, data, callbacks, metrics)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[1;34m(model, xb, yb, loss_fn, opt, cb_handler, metrics)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO use clr \n",
    "# fit_one_cycle fits a model following the 1cycle policy.\n",
    "learn.fit_one_cycle(2, lr)#.fit(1, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-23T10:58:26.564284Z",
     "start_time": "2018-09-23T10:58:26.547745Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "###RUN THROUGH DL2 TRANSLATE NOTEBOOK AND ANSWER THESE QUESTIONS\n",
    "#########################################\n",
    "## WHAT IS \n",
    "\n",
    "#vecs_enc - \n",
    "    # Dict of words, with embedding vectors values\n",
    "    # https://i.imgur.com/nIELpdY.png\n",
    "    # https://i.imgur.com/RgBnu4O.png\n",
    "#itos_enc - \n",
    "    # Index to string\n",
    "    # List of strings, of which the list index is pointing to a word\n",
    "    # https://i.imgur.com/oq6Kcv1.png\n",
    "    # https://i.imgur.com/dXSh60V.png\n",
    "#vecs_dec - Same as vecs_enc, but for dec\n",
    "#itos_dec - Same as itos_enc but for dec\n",
    "#########################################\n",
    "##WHAT DOES create_emb DO\n",
    "    # Makes an embedding with wiki vectors weights tripled \n",
    "## WHAT IS THE sl,bs IN inp.size()\n",
    "    # bs is batch size\n",
    "    # sl is seq_len https://i.imgur.com/icfxqv9.png\n",
    "\n",
    "##WHAT DOES THE FOR LOOP IN FORWARD DO\n",
    "    # Get encoder input values from embeddings\n",
    "    # Send enc hidden and embedding to decoder gru\n",
    "    # Get highest value per patch\n",
    "    # Append to result\n",
    "\n",
    "##WHY DO YOU TAKE WEIGHT DATA OF OUTPUT EMBEDDINGS (IS THAT RELATED TO THE RETURN?)\n",
    "\n",
    "\n",
    "##########################################\n",
    "###FIGURE OUT THE LOSS FUNCTION\n",
    "    # Commented\n",
    "    ## WHY DO YOU PAD THE INPUT LIKE THAT\n",
    "        # Commented\n",
    "    ## WHY DO YOU SLICE THE INPUT\n",
    "        # Commented\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:25.249402Z",
     "start_time": "2018-09-22T11:58:25.247405Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONVERT IT TO BIDIR\n",
    "    # Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:08.624959Z",
     "start_time": "2018-09-22T11:58:08.622955Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEACHER FORCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:15.176179Z",
     "start_time": "2018-09-22T11:58:15.174175Z"
    }
   },
   "outputs": [],
   "source": [
    "# ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:34.922938Z",
     "start_time": "2018-09-22T11:58:34.920934Z"
    }
   },
   "outputs": [],
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN PROPERLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:59:06.256912Z",
     "start_time": "2018-09-22T11:59:06.254906Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONVERT MODEL TO PRDOCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_itos = dict(map(reversed, en_tokenizer.word_index.items()))\n",
    "ru_itos = dict(map(reversed, ru_tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_bos_ we're all infected. _eos_\n",
      "_bos_ мы все заражены. _eos_\n",
      "_bos_ том не не _eos_\n",
      "\n",
      "_bos_ tom was sitting on the edge of the bed. _eos_\n",
      "_bos_ том сидел на OOV кровати. _eos_\n",
      "_bos_ я не _eos_ _eos_\n",
      "\n",
      "_bos_ i'll stop now. _eos_\n",
      "_bos_ я остановлюсь сейчас. _eos_\n",
      "_bos_ я не тут. _eos_\n",
      "\n",
      "_bos_ why do we have to wait? _eos_\n",
      "_bos_ почему мы должны ждать? _eos_\n",
      "_bos_ я не не _eos_ _eos_\n",
      "\n",
      "_bos_ tom ducked his head. _eos_\n",
      "_bos_ том пригнул голову. _eos_\n",
      "_bos_ я не не _eos_\n",
      "\n",
      "_bos_ i lived there for three years. _eos_\n",
      "_bos_ я прожил там три года. _eos_\n",
      "_bos_ я _eos_ не _eos_\n",
      "\n",
      "_bos_ we are suffering from a severe water shortage this summer. _eos_\n",
      "_bos_ мы страдаем от серьёзного дефицита воды этим летом. _eos_\n",
      "_bos_ том не не _eos_\n",
      "\n",
      "_bos_ i don't even think about it anymore. _eos_\n",
      "_bos_ я и не думаю об этом больше. _eos_\n",
      "_bos_ я не не _eos_\n",
      "\n",
      "_bos_ it's all i need. _eos_\n",
      "_bos_ это всё, что мне нужно. _eos_\n",
      "_bos_ я не низкий. _eos_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(dl_val))\n",
    "probs = learn.model(x.cuda())\n",
    "preds = probs.max(2)[1].cpu().numpy()\n",
    "x,y = x.cpu().numpy(), y.cpu().numpy()\n",
    "\n",
    "for i in range(1,10):\n",
    "    print(' '.join([en_itos[o] for o in x[i, :] if o != 0]))\n",
    "    print(' '.join([ru_itos[o] for o in y[i, :] if o != 0]))\n",
    "    print(' '.join([ru_itos[o] for o in preds[i,:] if o!=0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (baseenv)",
   "language": "python",
   "name": "baseenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
