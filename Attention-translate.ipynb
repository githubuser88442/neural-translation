{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:01.597393Z",
     "start_time": "2018-09-27T16:39:59.994136Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import Dataset\n",
    "from fastai import DataBunch\n",
    "from fastai import Learner\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.enabled = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:01.601408Z",
     "start_time": "2018-09-27T16:40:01.598397Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:02.265669Z",
     "start_time": "2018-09-27T16:40:01.602410Z"
    }
   },
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path + 'rus.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[:-1]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"_bos_\" as the \"start of sequence\" token\n",
    "    # for the targets, and \"_eos_\" as \"end of sequence\" token\n",
    "    input_text = '_bos_ ' + input_text + ' _eos_'\n",
    "    target_text = '_bos_ ' + target_text + '_eos_'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "\n",
    "num_samples = len(input_texts)\n",
    "vocab_size = 50000\n",
    "\n",
    "from itertools import chain\n",
    "max_len = max(list(chain.from_iterable((len(x.split(' ')), len(y.split(' '))) for x, y in zip(input_texts, target_texts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:02.823120Z",
     "start_time": "2018-09-27T16:40:02.266672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 304513\n",
      "Max sequence length for inputs: 45\n",
      "Max sequence length for outputs: 41\n",
      "Median sequence length for inputs: 8.0\n",
      "Median sequence length for outputs: 6.0\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', num_samples)\n",
    "print('Max sequence length for inputs:', max([len(txt.split(' ')) for txt in input_texts]))\n",
    "print('Max sequence length for outputs:', max([len(txt.split(' ')) for txt in target_texts]))\n",
    "print('Median sequence length for inputs:', np.median([len(txt.split(' ')) for txt in input_texts]))\n",
    "print('Median sequence length for outputs:', np.median([len(txt.split(' ')) for txt in target_texts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.264198Z",
     "start_time": "2018-09-27T16:40:02.824122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 1\n",
      "241 1\n"
     ]
    }
   ],
   "source": [
    "en_tokenizer = Tokenizer(num_words=vocab_size, lower=True, split=' ', oov_token='OOV')\n",
    "ru_tokenizer = Tokenizer(num_words=vocab_size, lower=True, split=' ', oov_token='OOV')\n",
    "en_tokenizer.fit_on_texts(input_texts)\n",
    "ru_tokenizer.fit_on_texts(target_texts)\n",
    "\n",
    "x_t = np.asarray(en_tokenizer.texts_to_sequences(input_texts))\n",
    "y_t = np.asarray(ru_tokenizer.texts_to_sequences(target_texts))\n",
    "print(en_tokenizer.word_index['coffee'], en_tokenizer.word_index['OOV'])\n",
    "print(ru_tokenizer.word_index['кофе'], ru_tokenizer.word_index['OOV'])\n",
    "print(en_tokenizer.word_index['_bos_'], en_tokenizer.word_index['_bos_'])\n",
    "print(ru_tokenizer.word_index['_eos_'], ru_tokenizer.word_index['_eos_'])\n",
    "\n",
    "x_t = pad_sequences(x_t, maxlen=max_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "y_t = pad_sequences(y_t, maxlen=max_len, dtype='int32', padding='post', truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.272727Z",
     "start_time": "2018-09-27T16:40:20.265202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SOST Go. EOST', 'SOST Иди.EOST')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[0], target_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.281771Z",
     "start_time": "2018-09-27T16:40:20.273742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 39,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  2, 723,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0]),\n",
       " (304513, 45))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[0], y_t[0], x_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "x_trn, x_val, y_trn, y_val = train_test_split(x_t, y_t, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.393543Z",
     "start_time": "2018-09-27T16:40:20.283777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([274061, 45])\n",
      "y shape torch.Size([274061, 45])\n",
      "x shape torch.Size([30452, 45])\n",
      "y shape torch.Size([30452, 45])\n"
     ]
    }
   ],
   "source": [
    "bs=16\n",
    "\n",
    "class TokDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x; self.y = y\n",
    "        self.len = len(self.x)\n",
    "        self.x_data = torch.from_numpy(self.x); self.x_data = self.x_data.long()\n",
    "        self.y_data = torch.from_numpy(self.y); self.y_data = self.y_data.long()\n",
    "        print('x shape', self.x_data.shape)\n",
    "        print('y shape', self.y_data.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "ds = TokDataset(x_trn, y_trn)\n",
    "ds_val = TokDataset(x_val, y_val)\n",
    "dl = torch.utils.data.DataLoader(dataset=ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "dl_val = torch.utils.data.DataLoader(dataset=ds_val, batch_size=bs, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:40:20.410579Z",
     "start_time": "2018-09-27T16:40:20.394544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 16]) torch.Size([45, 16])\n"
     ]
    }
   ],
   "source": [
    "# Values for testing\n",
    "test_values = iter(dl)\n",
    "xs, ys = next(test_values)\n",
    "xs, ys = xs.t(), ys.t()\n",
    "print(xs.shape, ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:42:38.089470Z",
     "start_time": "2018-09-27T16:42:37.999253Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionRNN(nn.Module):\n",
    "    def __init__(self, inp_sz, out_sz, em_sz, h_sz, n_l, voc_sz):\n",
    "        super().__init__()\n",
    "        self.em_sz, self.h_sz, self.n_l, self.inp_sz, self.out_sz, self.voc_sz = em_sz, h_sz, n_l, inp_sz, out_sz, voc_sz\n",
    "        # Encoder\n",
    "        self.enc_em = nn.Embedding(self.voc_sz, self.em_sz)\n",
    "        self.em_drp = nn.Dropout(0.15)\n",
    "        self.enc_gru = nn.GRU(self.em_sz, self.h_sz, num_layers=self.n_l, dropout=0.2)\n",
    "        self.enc_out = nn.Linear(self.h_sz, self.em_sz, bias=False)\n",
    "        self.enc_drp = nn.Dropout(0.3)\n",
    "        # Decoder\n",
    "        self.dec_em = nn.Embedding(self.voc_sz, self.em_sz)\n",
    "        self.dec_gru = nn.GRU(self.em_sz, self.em_sz, num_layers=self.n_l, dropout=0.2)\n",
    "        self.dec_out = nn.Linear(self.em_sz, self.voc_sz)\n",
    "        #self.out.weight.data = self.enc_em.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        # seq_len, bs\n",
    "        sl, bs = inp.shape\n",
    "        h = self.initHidden(bs)\n",
    "        x = self.em_drp(self.enc_em(inp))\n",
    "        enc_gru_out, h = self.enc_gru(x, h)\n",
    "        h = self.enc_drp(self.enc_out(h))\n",
    "        \n",
    "        dec_inp = torch.zeros(bs).long().cuda()\n",
    "        result = []\n",
    "        # What is this?\n",
    "        for i in range(self.out_sz):\n",
    "            # Get embedding\n",
    "            emb = self.dec_em(dec_inp).unsqueeze(0)\n",
    "            # Pass hidden state from (initially) self.enc_out and embedding to dec gru\n",
    "            outp, h = self.dec_gru(emb, h)\n",
    "            # Pass decoder output to dense, get probabilities of words in len of vocab_size\n",
    "            outp = self.dec_out(self.enc_drp(outp[0]))\n",
    "            result.append(outp)\n",
    "            # Get ind of biggest value for each batch \n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            # If all are padding break\n",
    "            if (dec_inp==0).all():\n",
    "                break\n",
    "        # Turn list of tensors into tensor\n",
    "        return torch.stack(result)\n",
    "    \n",
    "    def initHidden(self, bs): \n",
    "        # Num_layers, batch size, num hidden\n",
    "        return torch.zeros(self.n_l, bs, self.h_sz).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:42:39.160395Z",
     "start_time": "2018-09-27T16:42:38.783755Z"
    }
   },
   "outputs": [],
   "source": [
    "em_sz = 150\n",
    "n_h = 64\n",
    "n_l = 2\n",
    "\n",
    "inp_sz = max_len\n",
    "model = AttentionRNN(inp_sz, max_len, em_sz, n_h, n_l, vocab_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T16:42:40.645898Z",
     "start_time": "2018-09-27T16:42:40.023981Z"
    }
   },
   "outputs": [],
   "source": [
    "test_out = model(xs.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 16, 50000])\n",
      "torch.Size([47, 16, 50000])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test_out.shape)\n",
    "# Padding example\n",
    "print(torch.nn.functional.pad(test_out, (0,0,0,0,0,2)).shape)\n",
    "# Last seq_len value is padded, so the sum of the vocab_size probs is 0\n",
    "print(int(torch.sum(torch.nn.functional.pad(test_out, (0,0,0,0,0,2))[-1].view(-1)).data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://course.fast.ai/lessons/lesson11.html\n",
    "# http://forums.fast.ai/t/part-2-lesson-11-wiki/14699\n",
    "# 1 hour in\n",
    "def seq2seq_loss(input, target):\n",
    "    # seq_len, bs\n",
    "    sl,bs = target.size()\n",
    "    # seq_len, bs, num_channels (vocab size)\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    # If the output sl is smaller than the actual sl, pad it.\n",
    "    # The shape of input is 'sl x bs x vocab_sz'\n",
    "    # The reason why have more 0's for padding, is because in PyTorch\n",
    "    # You have padding on the left, and right, so none on sl or bs or nc left side, but pad on right\n",
    "    # In this case, pad seq_len on the right by the difference between grount truth sl and input sl\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    # If its too long, just crop it\n",
    "    input = input[:sl]\n",
    "    # Cross entropy expects a rank 2 tensor, so flatten the seq_len\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastai DataBunch and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_bunch = DataBunch(dl, dl_val)\n",
    "learn = Learner(d_bunch, model, loss_fn=seq2seq_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2986a42e21d340b3b58b1ffa343e0dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=1), HTML(value='0.00% [0/1 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use clr \n",
    "learn.fit(1, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-23T10:58:26.564284Z",
     "start_time": "2018-09-23T10:58:26.547745Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "###RUN THROUGH DL2 TRANSLATE NOTEBOOK AND ANSWER THESE QUESTIONS\n",
    "#########################################\n",
    "## WHAT IS \n",
    "\n",
    "#vecs_enc - \n",
    "    # Dict of words, with embedding vectors values\n",
    "    # https://i.imgur.com/nIELpdY.png\n",
    "    # https://i.imgur.com/RgBnu4O.png\n",
    "#itos_enc - \n",
    "    # Index to string\n",
    "    # List of strings, of which the list index is pointing to a word\n",
    "    # https://i.imgur.com/oq6Kcv1.png\n",
    "    # https://i.imgur.com/dXSh60V.png\n",
    "#vecs_dec - Same as vecs_enc, but for dec\n",
    "#itos_dec - Same as itos_enc but for dec\n",
    "#########################################\n",
    "##WHAT DOES create_emb DO\n",
    "    # Makes an embedding with wiki vectors weights tripled \n",
    "## WHAT IS THE sl,bs IN inp.size()\n",
    "    # bs is batch size\n",
    "    # sl is seq_len https://i.imgur.com/icfxqv9.png\n",
    "\n",
    "##WHAT DOES THE FOR LOOP IN FORWARD DO\n",
    "    # Get encoder input values from embeddings\n",
    "    # Send enc hidden and embedding to decoder gru\n",
    "    # Get highest value per patch\n",
    "    # Append to result\n",
    "\n",
    "##WHY DO YOU TAKE WEIGHT DATA OF OUTPUT EMBEDDINGS (IS THAT RELATED TO THE RETURN?)\n",
    "\n",
    "\n",
    "##########################################\n",
    "###FIGURE OUT THE LOSS FUNCTION\n",
    "\n",
    "## WHY DO YOU PAD THE INPUT LIKE THAT\n",
    "\n",
    "## WHY DO YOU SLICE THE INPUT\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:46.624860Z",
     "start_time": "2018-09-22T11:58:46.622855Z"
    }
   },
   "outputs": [],
   "source": [
    "# TRY TO TRAIN IT, WRITE OWN TRAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:25.249402Z",
     "start_time": "2018-09-22T11:58:25.247405Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONVERT IT TO BIDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:08.624959Z",
     "start_time": "2018-09-22T11:58:08.622955Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEACHER FORCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:15.176179Z",
     "start_time": "2018-09-22T11:58:15.174175Z"
    }
   },
   "outputs": [],
   "source": [
    "# ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:58:34.922938Z",
     "start_time": "2018-09-22T11:58:34.920934Z"
    }
   },
   "outputs": [],
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T11:59:06.256912Z",
     "start_time": "2018-09-22T11:59:06.254906Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONVERT MODEL TO PRDOCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_itos = dict(map(reversed, en_tokenizer.word_index.items()))\n",
    "ru_itos = dict(map(reversed, ru_tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sost i kept my word eost\n",
      "sost я сдержал слово eost\n",
      "sost я не eost eost eost\n",
      "\n",
      "sost i must work hard to make up for lost time eost\n",
      "sost я должен много работать чтобы нагнать потерянное время eost\n",
      "sost я не eost eost eost\n",
      "\n",
      "sost you're a very handsome man eost\n",
      "sost вы очень красивый мужчина eost\n",
      "sost я не eost eost eost\n",
      "\n",
      "sost tom said he was going to talk to mary eost\n",
      "sost том сказал что собирается поговорить с мэри eost\n",
      "sost я не eost eost eost\n",
      "\n",
      "sost are you coming tomorrow eost\n",
      "sost ты завтра придёшь eost\n",
      "sost я не eost eost eost\n",
      "\n",
      "sost i have a dentist appointment eost\n",
      "sost я записан на приём к дантисту eost\n",
      "sost я не eost eost eost\n",
      "\n",
      "sost tom thought you were busy eost\n",
      "sost том думал что вы заняты eost\n",
      "sost я не eost eost eost\n",
      "\n",
      "sost when will you begin eost\n",
      "sost когда начнёшь eost\n",
      "sost я не eost eost eost\n",
      "\n",
      "sost bring me my bag eost\n",
      "sost принесите мне мою сумку eost\n",
      "sost я не eost eost eost\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(dl_val))\n",
    "probs = learn.model(x.cuda())\n",
    "preds = probs.max(2)[1].cpu().numpy()\n",
    "x,y = x.cpu().numpy(), y.cpu().numpy()\n",
    "\n",
    "for i in range(1,10):\n",
    "    print(' '.join([en_itos[o] for o in x[i, :] if o != 0]))\n",
    "    print(' '.join([ru_itos[o] for o in y[i, :] if o != 0]))\n",
    "    print(' '.join([ru_itos[o] for o in preds[i,:] if o!=0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (baseenv)",
   "language": "python",
   "name": "baseenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
